{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENrscIKeF0Ah",
        "outputId": "27d98013-bb35-427b-ff64-24875ec3e829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9985\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1995\n",
            "           1       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      0.70      0.79      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [08:35:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.999\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1995\n",
            "           1       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      0.80      0.87      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/synthetic_fake_profile_dataset.csv\")  # Adjust with your file path\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[\"profile_id\", \"suspicious_activity\"])\n",
        "y = df[\"suspicious_activity\"]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Random Forest\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    n_estimators=50,  # Limit boosting rounds for efficiency\n",
        "    subsample=0.8,  # Reduce training complexity\n",
        "    max_depth=6  # Balance complexity and performance\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate XGBoost\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, xgb_predictions))\n"
      ]
    }
  ]
}